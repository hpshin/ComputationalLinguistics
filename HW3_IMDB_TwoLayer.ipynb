{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 IMDB + Two Layer Net\n",
    "\n",
    "- 수업시간에 다룬 Two Layer Net를 이용하여 HW2에서 다룬 IMDB 데이터를 학습하고 테스트 하는 프로그램 작성\n",
    "- IMDB 데이터에 필요한 vocab.txt는 제공됨\n",
    "- IMDB 데이터는 이 노트북과 같은 디렉토리에 있고 현재 디렉토리 밑에 txt_sentoken/pos, txt_sentoken/neg에 해당 파일이 있는 것으로 하고 프로그래밍할 것\n",
    "- 제출시에는 데이터 파일은 제출할 필요가 없음\n",
    "- Two Layer Net에서는 필요한 클래스, 모듈은 이 노트북에 명시되어야 함. import해서는 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMDB 데이터를 위한 함수 구현 \n",
    "## https://machinelearningmastery.com/prepare-movie-review-data-sentiment-analysis/ 에서 그대로 가져다 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## vocab.txt를 불러와서 실제로 사용될 vocab을 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load all training reviews\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load all test reviews\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##deep_learning_from_scratch github에 ch05에 있는 two_layer_net.py를 근간으로 하고 \n",
    "## 필요한 class는 common 디렉토리 밑에 있는 functions.py, layer.py 등을 참조\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict(self, x):\n",
    "        \n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "       \n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        \n",
    "        \n",
    "\n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \n",
    "        \n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "class Relu:\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    \n",
    "    \n",
    "\n",
    "class Affine:\n",
    "    \n",
    "    \n",
    "    \n",
    "class SoftmaxWithLoss:\n",
    "    \n",
    "    \n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    \n",
    "    \n",
    "\n",
    "def sigmoid(x):\n",
    "    \n",
    "    \n",
    "def softmax(x):\n",
    "    \n",
    "    \n",
    "\n",
    "def _numerical_gradient_1d(f, x):\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def numerical_gradient_2d(f, X):\n",
    "    \n",
    "    \n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##training \n",
    "## ch05에 있는 train_neuralnet.py를 이 데이터에 맞도록 수정하여 사용.\n",
    "training accuracy와 test accuracy를 매 epoch마다 출력"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
